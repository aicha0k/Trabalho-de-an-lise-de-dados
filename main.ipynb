{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho Final de Aprendizado de Máquina\n",
    "### Aluna: Aicha Khalid Hassan Al-Rob\n",
    "\n",
    "##### Este trabalho utilizará como base um dataset de cinco milhões de letras de músicas, trazidos de um site de letras de músicas. O objetivo é criar um modelo de aprendizado de máquina que consiga prever o gênero musical de uma letra de música, baseado em seu conteúdo.\n",
    "\n",
    "Vamos, primeiro, importar as bibliotecas necessárias para o trabalho.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "import requests\n",
    "import kaggle\n",
    "import pickle\n",
    "from random import seed, sample\n",
    "import glob\n",
    "import os\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.read_csv('spotify_millsongdata.csv', chunksize=100000)\n",
    "my_data = pd.concat(my_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57650 entries, 0 to 57649\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   artist  57650 non-null  object\n",
      " 1   song    57650 non-null  object\n",
      " 2   link    57650 non-null  object\n",
      " 3   text    57650 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "my_data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos ao pré processamento dos dados. Primeiro, vamos ler o dataset e ver como ele está estruturado."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como este dataset é muito grande, utilizar o método do pandas 'read_csv()' não se aplica aqui. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader():\n",
    "    def __init__(self,input_path,output_path):\n",
    "        self.input_path = input_path\n",
    "        self.output_path = output_path\n",
    "        self.chunksize = 10000\n",
    "\n",
    "    def produce_pickles(self):\n",
    "        with pd.read_csv(self.input_path, chunksize= self.chunksize) as reader:\n",
    "            try:\n",
    "                os.makedirs(self.output_path)\n",
    "            except FileExistsError:\n",
    "                pass # diretorio ja existe\n",
    "            for i, chunk in enumerate(reader):\n",
    "                out_file = self.output_path + f'/chunk{i}.pkl'\n",
    "                with open(out_file, \"wb\") as file:\n",
    "                    pickle.dump(chunk,file, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        # with pd.read_csv(self.input_path, chunksize=self.chunksize) as reader:\n",
    "        #     for i, chunk in enumerate(reader):\n",
    "        #         chunk.to_pickle(self.output_path + f'chunk{i}.pkl')\n",
    "\n",
    "    def load_pickle(self, pickle_id): # carrega um arquivo pickle de acordo com o id fornecido\n",
    "        # se diretorio estiver vazio ou nao existir\n",
    "        if (not os.path.exists(self.output_path)) or (len(os.listdir(self.output_path)) == 0):\n",
    "            self.produce_pickles()\n",
    "        \n",
    "        file_path = self.output_path + \"/chunk\" + str(pickle_id) + \".pkl\"\n",
    "        if os.path.isfile(file_path):\n",
    "            my_df = pd.read_pickle(file_path)\n",
    "        else:\n",
    "            raise Exception(f\"O arquivo chunk{pickle_id}.pkl não existe\")\n",
    "        return my_df         \n",
    "    \n",
    "    def random_pickles(self, n_pickles=3, init=42, verbose=True):\n",
    "        # faz a leitura aleatoria de pickles. \n",
    "        # n_pickles sao a quantidade a ser carregada, init é um parametro pra randomização da leitura\n",
    "        # verbose é uma booleana, se for true, mostra no terminal os arquivos carregados.\n",
    " \n",
    "        if (not os.path.exists(self.output_path)) or (len(os.listdir(self.output_path)) == 0):\n",
    "            self.produce_pickles()\n",
    "        \n",
    "        pickle_files = []\n",
    "        for name in glob.glob(self.output_path + \"chunk*.pkl\"):\n",
    "            pickle_files.append(name)\n",
    "            print(len(pickle_files))\n",
    "        \n",
    "        seed(init)\n",
    "\n",
    "        if len(pickle_files) >= n_pickles:\n",
    "            random_p_files = sample(pickle_files, n_pickles)\n",
    "        else:\n",
    "            raise Exception(\"A quantidade de pickles fornecida excede o numero de arquivos pickle\")\n",
    "\n",
    "        df_list = []\n",
    "        for pickle in random_p_files:\n",
    "            pd.read_pickle(pickle) \n",
    "\n",
    "        my_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Pickles carregados na memória:\")\n",
    "            for pickle in random_p_files:\n",
    "                print(pickle)\n",
    "        \n",
    "        return my_df\n",
    "    \n",
    "    def find_pickles(self, num,):\n",
    "        # verifica se arquivo existe\n",
    "        if (not os.path.exists(self.output_path)) or (len(os.listdir(self.output_path)) == 0):\n",
    "            self.produce_pickles()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_input = './song_lyrics.csv'\n",
    "my_ouput = './output/data'\n",
    "\n",
    "my_loader = Loader(input_path=my_input, output_path=my_ouput)\n",
    "\n",
    "my_data = my_loader.random_pickles(n_pickles=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"O dataframe está com {my_data.shape[0]} linhas e {my_data.shape[1]} colunas\")\n",
    "print(f\"Numero de itens (musicas) únicos: {len(my_data.id.unique())}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea33adf5b232487cd1c779bb7b73588b2b17e587c5d7b2e690488b2ce734e515"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
